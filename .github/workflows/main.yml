name: Smart Pivot Cache Extract (Full Decode + Export XLSX to Pivot_To_Month)

on:
  workflow_dispatch:

jobs:
  extract:
    runs-on: ubuntu-latest

    steps:
      - name: Setup Python
        uses: actions/setup-python@v5
        with:
          python-version: 3.11

      - name: Install dependencies
        run: |
          pip install pandas pyarrow openpyxl lxml requests

      - name: Run Full Smart Pivot Extract + Export XLSX
        env:
          TENANT_ID: ${{ secrets.TENANT_ID }}
          CLIENT_ID: ${{ secrets.CLIENT_ID }}
          CLIENT_SECRET: ${{ secrets.CLIENT_SECRET }}
          USER_EMAIL: "tiennm@tuanvietc5.id.vn"
          SRC_FOLDER: "/1.Job/2425/1. Tracking/Pivot_Month_Par"
          OUT_FOLDER: "/1.Job/2425/1. Tracking/Pivot_To_Month"
        run: |
          python - <<'PYCODE'
          import os, io, zipfile, requests, pandas as pd
          from lxml import etree

          TENANT_ID = os.environ["TENANT_ID"]
          CLIENT_ID = os.environ["CLIENT_ID"]
          CLIENT_SECRET = os.environ["CLIENT_SECRET"]
          USER_EMAIL = os.environ["USER_EMAIL"]
          SRC_FOLDER = os.environ["SRC_FOLDER"]
          OUT_FOLDER = os.environ["OUT_FOLDER"]
          GRAPH_API = "https://graph.microsoft.com/v1.0"

          print("ðŸ” Láº¥y access token ...")
          token_url = f"https://login.microsoftonline.com/{TENANT_ID}/oauth2/v2.0/token"
          token_data = {
              "grant_type": "client_credentials",
              "client_id": CLIENT_ID,
              "client_secret": CLIENT_SECRET,
              "scope": "https://graph.microsoft.com/.default",
          }
          token_res = requests.post(token_url, data=token_data)
          if not token_res.ok:
              print("âŒ KhÃ´ng láº¥y Ä‘Æ°á»£c token:", token_res.text)
              exit(1)
          token = token_res.json().get("access_token")
          headers = {"Authorization": f"Bearer {token}"}

          # ===== Láº¥y Drive ID =====
          drive_info = requests.get(f"{GRAPH_API}/users/{USER_EMAIL}/drive", headers=headers).json()
          if "id" not in drive_info:
              print("âŒ KhÃ´ng láº¥y Ä‘Æ°á»£c Drive ID:", drive_info)
              exit(1)
          drive_id = drive_info["id"]
          print("ðŸ“ Drive ID:", drive_id)

          # ===== Láº¥y danh sÃ¡ch file trong thÆ° má»¥c nguá»“n =====
          encoded_path = requests.utils.quote(SRC_FOLDER)
          list_url = f"{GRAPH_API}/drives/{drive_id}/root:{encoded_path}:/children"
          res = requests.get(list_url, headers=headers)
          if not res.ok:
              print("âŒ Lá»—i láº¥y danh sÃ¡ch:", res.text)
              exit(1)

          items = res.json().get("value", [])
          xlsx_files = [i for i in items if i["name"].lower().endswith(".xlsx")]
          print(f"ðŸ”Ž TÃ¬m tháº¥y {len(xlsx_files)} file trong {SRC_FOLDER}")

          for f in xlsx_files:
              name = f["name"]
              print(f"\nðŸ“¥ Äang xá»­ lÃ½: {name}")

              dl_url = f"{GRAPH_API}/drives/{drive_id}/items/{f['id']}/content"
              resp = requests.get(dl_url, headers=headers)
              if resp.status_code != 200:
                  print(f"âŒ Lá»—i táº£i file {name}: {resp.status_code}")
                  continue
              excel_bytes = resp.content

              if excel_bytes[:4] != b'PK\x03\x04':
                  print(f"âš ï¸ {name} khÃ´ng pháº£i Excel há»£p lá»‡.")
                  continue

              try:
                  with zipfile.ZipFile(io.BytesIO(excel_bytes)) as z:
                      record_files = [p for p in z.namelist() if "pivotCacheRecords" in p]
                      if not record_files:
                          print("âš ï¸ KhÃ´ng cÃ³ pivotCacheRecords trong file.")
                          continue

                      for rec in record_files:
                          print(f"ðŸ” Bung {rec} ...")

                          def_path = rec.replace("Records", "Definition")
                          if def_path not in z.namelist():
                              print("âš ï¸ KhÃ´ng tÃ¬m tháº¥y Definition tÆ°Æ¡ng á»©ng.")
                              continue

                          def_xml = etree.fromstring(z.read(def_path))
                          ns = {"d": "http://schemas.openxmlformats.org/spreadsheetml/2006/main"}

                          # ===== Láº¥y sharedItems + tÃªn cá»™t =====
                          fields = []
                          shared_lookup = []
                          for fnode in def_xml.findall(".//d:cacheField", ns):
                              name_field = fnode.get("name") or fnode.get("caption") or "Field"
                              shared = []
                              si = fnode.find(".//d:sharedItems", ns)
                              if si is not None:
                                  for item in si:
                                      tag = etree.QName(item).localname
                                      val = None
                                      if tag == "s":
                                          val = item.get("v") or item.text
                                      elif tag == "n":
                                          try:
                                              val = float(item.get("v") or item.text or 0)
                                          except:
                                              val = item.get("v") or item.text
                                      elif tag == "b":
                                          val = "TRUE" if item.get("v") == "1" else "FALSE"
                                      shared.append(val)
                              shared_lookup.append(shared)
                              fields.append(name_field)

                          # ===== Äá»c pivotCacheRecords =====
                          root = etree.fromstring(z.read(rec))
                          rows = []
                          for row in root.findall(".//d:r", ns):
                              row_values = []
                              for i, cell in enumerate(row):
                                  tag = etree.QName(cell).localname
                                  v_attr = cell.get("v")
                                  val = None
                                  if tag == "x" and v_attr is not None:
                                      try:
                                          idx = int(v_attr)
                                          if i < len(shared_lookup) and idx < len(shared_lookup[i]):
                                              val = shared_lookup[i][idx]
                                          else:
                                              val = idx
                                      except:
                                          val = v_attr
                                  elif tag == "s":
                                      val = v_attr or cell.text
                                  elif tag == "n":
                                      try:
                                          val = float(v_attr or cell.text or 0)
                                      except:
                                          val = v_attr
                                  elif tag == "b":
                                      val = "TRUE" if (v_attr == "1" or cell.text == "1") else "FALSE"
                                  row_values.append(val)
                              rows.append(row_values)

                          if not rows:
                              print("âš ï¸ Cache rá»—ng.")
                              continue

                          df = pd.DataFrame(rows, columns=fields)
                          print(f"âœ… Bung Ä‘Æ°á»£c {len(df)} dÃ²ng tá»« {name}")

                          # ===== Ghi file Parquet =====
                          out_parquet = name.replace(".xlsx", "_cache.parquet")
                          buf_par = io.BytesIO()
                          df.to_parquet(buf_par, index=False)
                          buf_par.seek(0)
                          upload_parquet_url = f"{GRAPH_API}/drives/{drive_id}/root:{SRC_FOLDER}/{out_parquet}:/content?@microsoft.graph.conflictBehavior=replace"
                          up = requests.put(upload_parquet_url, headers=headers, data=buf_par)
                          if up.ok:
                              print(f"ðŸ“¤ ÄÃ£ ghi {out_parquet} thÃ nh cÃ´ng (overwrite).")
                          else:
                              print(f"âŒ Lá»—i ghi {out_parquet}:", up.text)

                          # ===== Ghi file XLSX vÃ o Pivot_To_Month =====
                          out_xlsx = name.replace(".xlsx", "_cache.xlsx")
                          buf_xlsx = io.BytesIO()
                          with pd.ExcelWriter(buf_xlsx, engine="openpyxl") as writer:
                              df.to_excel(writer, index=False, sheet_name="Detail")
                          buf_xlsx.seek(0)
                          upload_xlsx_url = f"{GRAPH_API}/drives/{drive_id}/root:{OUT_FOLDER}/{out_xlsx}:/content?@microsoft.graph.conflictBehavior=replace"
                          upx = requests.put(upload_xlsx_url, headers=headers, data=buf_xlsx)
                          if upx.ok:
                              print(f"ðŸ“— ÄÃ£ ghi {out_xlsx} vÃ o Pivot_To_Month (sheet Detail).")
                          else:
                              print(f"âŒ Lá»—i ghi {out_xlsx}:", upx.text)

              except Exception as e:
                  print(f"âŒ Lá»—i khi xá»­ lÃ½ {name}: {e}")

          print("\nðŸ HoÃ n táº¥t bung Pivot Cache vÃ  ghi XLSX vÃ o Pivot_To_Month.")
          PYCODE
