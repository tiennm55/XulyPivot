for idx, f in enumerate(xlsx_files, start=1):
    name = f["name"]
    file_id = f["id"]
    print(f"\nüì• ƒêang x·ª≠ l√Ω: {name}")

    dl_url = f"{GRAPH_API}/drives/{drive_id}/items/{file_id}/content"
    resp = requests.get(dl_url, headers=headers)
    if resp.status_code != 200:
        print(f"‚ùå L·ªói t·∫£i file {name}: {resp.status_code}")
        continue
    excel_bytes = resp.content

    if excel_bytes[:4] != b'PK\x03\x04':
        print(f"‚ö†Ô∏è {name} kh√¥ng ph·∫£i Excel h·ª£p l·ªá.")
        continue

    try:
        with zipfile.ZipFile(io.BytesIO(excel_bytes)) as z:
            record_files = [p for p in z.namelist() if "pivotCacheRecords" in p]
            if not record_files:
                print("‚ö†Ô∏è Kh√¥ng c√≥ pivotCacheRecords trong file.")
                continue

            for rec in record_files:
                print(f"üîç Bung {rec} ...")

                def_path = rec.replace("Records", "Definition")
                if def_path not in z.namelist():
                    print("‚ö†Ô∏è Kh√¥ng t√¨m th·∫•y Definition t∆∞∆°ng ·ª©ng.")
                    continue

                def_xml = etree.fromstring(z.read(def_path))
                ns = {"d": "http://schemas.openxmlformats.org/spreadsheetml/2006/main"}

                # ===== L·∫•y sharedItems + t√™n c·ªôt =====
                fields = []
                shared_lookup = []
                for fnode in def_xml.findall(".//d:cacheField", ns):
                    name_field = fnode.get("name") or fnode.get("caption") or "Field"
                    shared = []
                    si = fnode.find(".//d:sharedItems", ns)
                    if si is not None:
                        for item in si:
                            tag = etree.QName(item).localname
                            val = None
                            if tag == "s":
                                val = item.get("v") or item.text
                            elif tag == "n":
                                try:
                                    val = float(item.get("v") or item.text or 0)
                                except:
                                    val = item.get("v") or item.text
                            elif tag == "b":
                                val = "TRUE" if item.get("v") == "1" else "FALSE"
                            shared.append(val)
                    shared_lookup.append(shared)
                    fields.append(name_field)

                # ===== ƒê·ªçc pivotCacheRecords =====
                root = etree.fromstring(z.read(rec))
                rows = []
                for row in root.findall(".//d:r", ns):
                    row_values = []
                    for i, cell in enumerate(row):
                        tag = etree.QName(cell).localname
                        v_attr = cell.get("v")
                        val = None
                        if tag == "x" and v_attr is not None:
                            try:
                                idx_val = int(v_attr)
                                if i < len(shared_lookup) and idx_val < len(shared_lookup[i]):
                                    val = shared_lookup[i][idx_val]
                                else:
                                    val = idx_val
                            except:
                                val = v_attr
                        elif tag == "s":
                            val = v_attr or cell.text
                        elif tag == "n":
                            try:
                                val = float(v_attr or cell.text or 0)
                            except:
                                val = v_attr
                        elif tag == "b":
                            val = "TRUE" if (v_attr == "1" or cell.text == "1") else "FALSE"
                        row_values.append(val)
                    rows.append(row_values)

                if not rows:
                    print("‚ö†Ô∏è Cache r·ªóng.")
                    continue

                df = pd.DataFrame(rows, columns=fields)
                print(f"‚úÖ Bung ƒë∆∞·ª£c {len(df)} d√≤ng t·ª´ {name}")

                # ===== Quy t·∫Øc ƒë·∫∑t t√™n m·ªõi =====
                file_index = str(idx).zfill(2)  # 01, 02, 03,...
                out_xlsx = f"Detail_{file_index}.xlsx"
                out_parquet = f"Detail_{file_index}.parquet"

                # ===== Ghi file Parquet =====
                buf_par = io.BytesIO()
                df.to_parquet(buf_par, index=False)
                buf_par.seek(0)
                upload_parquet_url = f"{GRAPH_API}/drives/{drive_id}/root:{OUT_PARQUET_FOLDER}/{out_parquet}:/content?@microsoft.graph.conflictBehavior=replace"
                up = requests.put(upload_parquet_url, headers=headers, data=buf_par)
                if up.ok:
                    print(f"üì§ ƒê√£ ghi {out_parquet} v√†o Pivot_Month_Par.")
                else:
                    print(f"‚ùå L·ªói ghi {out_parquet}:", up.text)
                    continue

                # ===== Ghi file XLSX =====
                buf_xlsx = io.BytesIO()
                with pd.ExcelWriter(buf_xlsx, engine="openpyxl") as writer:
                    df.to_excel(writer, index=False, sheet_name="Detail")
                buf_xlsx.seek(0)
                upload_xlsx_url = f"{GRAPH_API}/drives/{drive_id}/root:{OUT_XLSX_FOLDER}/{out_xlsx}:/content?@microsoft.graph.conflictBehavior=replace"
                upx = requests.put(upload_xlsx_url, headers=headers, data=buf_xlsx)
                if upx.ok:
                    print(f"üìó ƒê√£ ghi {out_xlsx} v√†o Pivot_To_Month.")
                    processed_files.append({"id": file_id, "name": name})
                else:
                    print(f"‚ùå L·ªói ghi {out_xlsx}:", upx.text)
    except Exception as e:
        print(f"‚ùå L·ªói khi x·ª≠ l√Ω {name}: {e}")
