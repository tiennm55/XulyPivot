name: Extract Pivot Cache to Excel and Parquet

on:
  workflow_dispatch:

jobs:
  extract:
    runs-on: ubuntu-latest
    steps:
      - name: Setup Python
        uses: actions/setup-python@v5
        with:
          python-version: 3.11

      - name: Install dependencies
        run: |
          pip install requests pandas lxml pyarrow

      - name: Run pivot cache extractor
        env:
          TENANT_ID: ${{ secrets.TENANT_ID }}
          CLIENT_ID: ${{ secrets.CLIENT_ID }}
          CLIENT_SECRET: ${{ secrets.CLIENT_SECRET }}
          USER_EMAIL: ${{ secrets.USER_EMAIL }}
          SRC_FOLDER: "/1.Job/2425/1. Tracking/Pivot_Month_Par"
          OUT_XLSX: "/1.Job/2425/1. Tracking/Pivot_Month"
        run: |
          python - <<'PYCODE'
          import io, os, requests, zipfile, pandas as pd
          from lxml import etree

          # ====== Cáº¥u hÃ¬nh OAuth ======
          TENANT_ID = os.environ["TENANT_ID"]
          CLIENT_ID = os.environ["CLIENT_ID"]
          CLIENT_SECRET = os.environ["CLIENT_SECRET"]
          USER_EMAIL = os.environ["USER_EMAIL"]
          SRC_FOLDER = os.environ["SRC_FOLDER"]
          OUT_XLSX = os.environ["OUT_XLSX"]

          token_url = f"https://login.microsoftonline.com/{TENANT_ID}/oauth2/v2.0/token"
          token_data = {
              "grant_type": "client_credentials",
              "client_id": CLIENT_ID,
              "client_secret": CLIENT_SECRET,
              "scope": "https://graph.microsoft.com/.default"
          }
          token = requests.post(token_url, data=token_data).json()["access_token"]
          headers = {"Authorization": f"Bearer {token}"}

          # ====== Láº¥y drive_id ======
          drives = requests.get("https://graph.microsoft.com/v1.0/me/drives", headers=headers).json()
          drive_id = drives["value"][0]["id"]
          print("ðŸ“ Drive ID:", drive_id)

          # ====== Láº¥y danh sÃ¡ch file trong thÆ° má»¥c nguá»“n ======
          list_url = f"https://graph.microsoft.com/v1.0/drives/{drive_id}/root:{SRC_FOLDER}:/children"
          files = requests.get(list_url, headers=headers).json().get("value", [])
          if not files:
              print("âš ï¸ KhÃ´ng tÃ¬m tháº¥y file nÃ o trong thÆ° má»¥c:", SRC_FOLDER)
              exit()

          # ====== Xá»­ lÃ½ tá»«ng file Excel ======
          for f in files:
              name = f["name"]
              if not name.lower().endswith(".xlsx"):
                  continue
              print(f"\nðŸ“¥ Äang bung Pivot Cache cá»§a: {name}")

              file_url = f"https://graph.microsoft.com/v1.0/drives/{drive_id}/root:{SRC_FOLDER}/{name}:/content"
              excel_bytes = requests.get(file_url, headers=headers).content

              try:
                  with zipfile.ZipFile(io.BytesIO(excel_bytes)) as z:
                      record_files = [f for f in z.namelist() if f.startswith("xl/pivotCache/pivotCacheRecords")]
                      if not record_files:
                          print("âš ï¸ KhÃ´ng tÃ¬m tháº¥y pivotCacheRecords trong file.")
                          continue

                      for record_file in record_files:
                          xml_data = z.read(record_file)
                          root = etree.fromstring(xml_data)
                          
                          # Parse XML pivot cache
                          ns = {"default": "http://schemas.openxmlformats.org/spreadsheetml/2006/main"}
                          records = []
                          for r in root.findall(".//default:r", namespaces=ns):
                              row = [c.text for c in r.findall(".//default:x", namespaces=ns)]
                              if row:
                                  records.append(row)

                          if not records:
                              print("âš ï¸ KhÃ´ng cÃ³ dá»¯ liá»‡u trong cache.")
                              continue

                          df = pd.DataFrame(records)
                          print(f"âœ… Bung Ä‘Æ°á»£c {len(df)} dÃ²ng tá»« cache.")

                          base_name = name.replace(".xlsx", "")
                          out_xlsx = f"{OUT_XLSX}/{base_name}_cache.xlsx"
                          out_parquet = f"{SRC_FOLDER}/{base_name}_cache.parquet"

                          # Ghi Excel
                          xlsx_buf = io.BytesIO()
                          df.to_excel(xlsx_buf, index=False)
                          xlsx_buf.seek(0)
                          requests.put(f"https://graph.microsoft.com/v1.0/drives/{drive_id}/root:{out_xlsx}:/content",
                                       headers=headers, data=xlsx_buf)
                          
                          # Ghi Parquet
                          pq_buf = io.BytesIO()
                          df.to_parquet(pq_buf, index=False)
                          pq_buf.seek(0)
                          requests.put(f"https://graph.microsoft.com/v1.0/drives/{drive_id}/root:{out_parquet}:/content",
                                       headers=headers, data=pq_buf)

                          print(f"ðŸ“¤ ÄÃ£ ghi {base_name}_cache.xlsx vÃ  .parquet thÃ nh cÃ´ng!")

              except Exception as e:
                  print(f"âŒ Lá»—i khi xá»­ lÃ½ {name}: {e}")

          print("ðŸ HoÃ n táº¥t bung toÃ n bá»™ Pivot Cache.")
          PYCODE
