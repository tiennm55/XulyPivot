name: Extract Pivot Cache to Excel and Parquet

on:
  workflow_dispatch:

jobs:
  extract:
    runs-on: ubuntu-latest
    steps:
      - name: Setup Python
        uses: actions/setup-python@v5
        with:
          python-version: 3.11

      - name: Install dependencies
        run: |
          pip install requests pandas lxml pyarrow openpyxl

      - name: Run Pivot Cache Extractor
        env:
          TENANT_ID: ${{ secrets.TENANT_ID }}
          CLIENT_ID: ${{ secrets.CLIENT_ID }}
          CLIENT_SECRET: ${{ secrets.CLIENT_SECRET }}
          USER_EMAIL: ${{ secrets.USER_EMAIL }}
          SRC_FOLDER: "/1.Job/2425/1. Tracking/Pivot_Month_Par"
          OUT_XLSX: "/1.Job/2425/1. Tracking/Pivot_Month"
        run: |
          python - <<'PYCODE'
          import io, os, zipfile, requests, pandas as pd
          from lxml import etree

          # ====== Cáº¥u hÃ¬nh OAuth ======
          TENANT_ID = os.environ["TENANT_ID"]
          CLIENT_ID = os.environ["CLIENT_ID"]
          CLIENT_SECRET = os.environ["CLIENT_SECRET"]
          USER_EMAIL = os.environ["USER_EMAIL"]
          SRC_FOLDER = os.environ["SRC_FOLDER"]
          OUT_XLSX = os.environ["OUT_XLSX"]

          token_url = f"https://login.microsoftonline.com/{TENANT_ID}/oauth2/v2.0/token"
          token_data = {
              "grant_type": "client_credentials",
              "client_id": CLIENT_ID,
              "client_secret": CLIENT_SECRET,
              "scope": "https://graph.microsoft.com/.default"
          }
          token = requests.post(token_url, data=token_data).json()["access_token"]
          headers = {"Authorization": f"Bearer {token}"}

          # ====== Láº¥y Drive ID ======
          user_drive = requests.get(
              f"https://graph.microsoft.com/v1.0/users/{USER_EMAIL}/drive",
              headers=headers
          ).json()
          if "id" not in user_drive:
              print("âŒ KhÃ´ng thá»ƒ láº¥y drive:", user_drive)
              exit(1)
          drive_id = user_drive["id"]
          print("ðŸ“ Drive ID:", drive_id)

          # ====== Láº¥y danh sÃ¡ch file trong Pivot_Month_Par ======
          list_url = f"https://graph.microsoft.com/v1.0/drives/{drive_id}/root:{SRC_FOLDER}:/children"
          res = requests.get(list_url, headers=headers).json()
          files = res.get("value", [])
          if not files:
              print("âš ï¸ KhÃ´ng tÃ¬m tháº¥y file nÃ o trong thÆ° má»¥c nguá»“n.")
              print("Response:", res)
              exit()

          for f in files:
              name = f["name"]
              if not name.lower().endswith(".xlsx"):
                  continue

              print(f"\nðŸ“¥ Äang xá»­ lÃ½ file: {name}")
              file_url = f"https://graph.microsoft.com/v1.0/drives/{drive_id}/root:{SRC_FOLDER}/{name}:/content"
              excel_bytes = requests.get(file_url, headers=headers).content

              try:
                  with zipfile.ZipFile(io.BytesIO(excel_bytes)) as z:
                      record_files = [f for f in z.namelist() if f.startswith("xl/pivotCache/pivotCacheRecords")]
                      if not record_files:
                          print("âš ï¸ KhÃ´ng tÃ¬m tháº¥y pivotCacheRecords trong file.")
                          continue

                      for record_file in record_files:
                          print(f"ðŸ” Äang Ä‘á»c {record_file} ...")
                          xml_data = z.read(record_file)
                          root = etree.fromstring(xml_data)
                          ns = {"d": "http://schemas.openxmlformats.org/spreadsheetml/2006/main"}

                          rows = []
                          for r in root.findall(".//d:r", namespaces=ns):
                              row_values = []
                              for c in r:
                                  tag = etree.QName(c).localname
                                  if tag == "x" or tag == "n":
                                      row_values.append(c.text)
                                  elif tag == "m":
                                      row_values.append(c.text)
                                  else:
                                      row_values.append(None)
                              rows.append(row_values)

                          if not rows:
                              print("âš ï¸ KhÃ´ng cÃ³ dá»¯ liá»‡u trong cache.")
                              continue

                          df = pd.DataFrame(rows)
                          print(f"âœ… Bung Ä‘Æ°á»£c {len(df)} dÃ²ng tá»« cache.")

                          base_name = name.replace(".xlsx", "")
                          out_xlsx = f"{OUT_XLSX}/{base_name}_cache.xlsx"
                          out_parquet = f"{SRC_FOLDER}/{base_name}_cache.parquet"

                          # Ghi Excel
                          buf_xlsx = io.BytesIO()
                          df.to_excel(buf_xlsx, index=False)
                          buf_xlsx.seek(0)
                          requests.put(f"https://graph.microsoft.com/v1.0/drives/{drive_id}/root:{out_xlsx}:/content",
                                       headers=headers, data=buf_xlsx)
                          
                          # Ghi Parquet
                          buf_parq = io.BytesIO()
                          df.to_parquet(buf_parq, index=False)
                          buf_parq.seek(0)
                          requests.put(f"https://graph.microsoft.com/v1.0/drives/{drive_id}/root:{out_parquet}:/content",
                                       headers=headers, data=buf_parq)

                          print(f"ðŸ“¤ ÄÃ£ ghi {base_name}_cache.xlsx vÃ  .parquet thÃ nh cÃ´ng.")

              except Exception as e:
                  print(f"âŒ Lá»—i khi xá»­ lÃ½ {name}: {e}")

          print("ðŸ HoÃ n táº¥t bung toÃ n bá»™ Pivot Cache.")
          PYCODE
